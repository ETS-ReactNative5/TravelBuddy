{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "GmaqeMj0eJhj"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import losses\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras import preprocessing\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "PITm_KSGeJhu"
      },
      "outputs": [],
      "source": [
        "main_data=pd.read_csv(\"train.csv\")\n",
        "data=main_data.copy()\n",
        "data.drop(columns=['id'],axis=1,inplace=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "c6EspigVeJh5"
      },
      "outputs": [],
      "source": [
        "data1=data[data['label']==1]\n",
        "data0=data[data['label']==0]\n",
        "data=pd.concat([data,data1,data1], axis=0) #This line duplicated the minority class data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mkblsrIGeJh9"
      },
      "outputs": [],
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    \n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "\n",
        "def clean_text(text ): \n",
        "    delete_dict = {sp_character: '' for sp_character in string.punctuation} \n",
        "    delete_dict[' '] = ' ' \n",
        "    table = str.maketrans(delete_dict)\n",
        "    text1 = text.translate(table)\n",
        "    textArr= text1.split()\n",
        "    text2 = ' '.join([w for w in textArr if ( not w.isdigit() and  ( not w.isdigit() and len(w)>2))]) \n",
        "    \n",
        "    return text2.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OwrRLa64eJiB"
      },
      "outputs": [],
      "source": [
        "data['text'] = data['text'].apply(remove_emoji)\n",
        "data['text'] = data['text'].apply(clean_text)\n",
        "data['Num_words_text'] = data['text'].apply(lambda x:len(str(x).split())) \n",
        "\n",
        "train_data,test_data= train_test_split(data, test_size=0.2)\n",
        "train_data.reset_index(drop=True,inplace=True)\n",
        "test_data.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czU60s3wqfeo"
      },
      "outputs": [],
      "source": [
        "#train and validation dataset splitting\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(train_data['text'].tolist(),\\\n",
        "                                                      train_data['label'].tolist(),\\\n",
        "                                                      test_size=0.2,\\\n",
        "                                                      stratify = train_data['label'].tolist(),\\\n",
        "                                                      random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IC6Mw9QveJiK"
      },
      "outputs": [],
      "source": [
        "num_words = 50000\n",
        "tokenizer = Tokenizer(num_words=num_words,oov_token=\"unk\")\n",
        "tokenizer.fit_on_texts(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1z5yKfRaqrP2"
      },
      "outputs": [],
      "source": [
        "x_train = np.array( tokenizer.texts_to_sequences(X_train) )\n",
        "x_valid = np.array( tokenizer.texts_to_sequences(X_valid) )\n",
        "x_test  = np.array( tokenizer.texts_to_sequences(test_data['twtexteet'].tolist()) )\n",
        "\n",
        "maxlen=50\n",
        "x_train = pad_sequences(x_train, padding='post', maxlen=maxlen)\n",
        "x_valid = pad_sequences(x_valid, padding='post', maxlen=maxlen)\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "\n",
        "train_labels = np.asarray(y_train)\n",
        "valid_labels = np.asarray(y_valid)\n",
        "test_labels = np.asarray(test_data['label'].tolist())\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((x_train,train_labels))\n",
        "valid_ds = tf.data.Dataset.from_tensor_slices((x_valid,valid_labels))\n",
        "test_ds = tf.data.Dataset.from_tensor_slices((x_test,test_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3o7cZ1hkqxiU"
      },
      "outputs": [],
      "source": [
        "#model preparation\n",
        "max_features =50000\n",
        "embedding_dim =16\n",
        "sequence_length = maxlen\n",
        "\n",
        "model = tf.keras.Sequential()\n",
        "model.add(tf.keras.layers.Embedding(max_features +1, embedding_dim, input_length=sequence_length, embeddings_regularizer = regularizers.l2(0.005))) \n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "\n",
        "model.add(tf.keras.layers.LSTM(embedding_dim,dropout=0.2, recurrent_dropout=0.2,return_sequences=True,kernel_regularizer=regularizers.l2(0.005),\\\n",
        "                                                             bias_regularizer=regularizers.l2(0.005)))\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(512, activation='relu',kernel_regularizer=regularizers.l2(0.001),\\\n",
        "                                bias_regularizer=regularizers.l2(0.001),))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(8, activation='relu',kernel_regularizer=regularizers.l2(0.001),\\\n",
        "                                bias_regularizer=regularizers.l2(0.001),))\n",
        "model.add(tf.keras.layers.Dropout(0.4))\n",
        "model.add(tf.keras.layers.Dense(1,activation='sigmoid'))\n",
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),optimizer=tf.keras.optimizers.Adam(1e-3),metrics=[tf.keras.metrics.BinaryAccuracy()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE5L1lopU3IT",
        "outputId": "ada65712-b5cf-4526-ee9f-d85180e08e68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9\n"
          ]
        }
      ],
      "source": [
        "print(len(model.layers))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b2SWOOYrFZc"
      },
      "outputs": [],
      "source": [
        "epochs = 10\n",
        "# Fit the model using the train and test datasets.\n",
        "history = model.fit(train_ds.shuffle(5000).batch(1024),\n",
        "                    epochs= epochs ,\n",
        "                    validation_data=valid_ds.batch(1024),\n",
        "                    verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Kdpl99Q2eJiV"
      },
      "outputs": [],
      "source": [
        "x_test  = np.array( tokenizer.texts_to_sequences(test_data['text'].tolist()) )\n",
        "x_test = pad_sequences(x_test, padding='post', maxlen=maxlen)\n",
        "predictions = model.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lFhAKLHurMrV"
      },
      "outputs": [],
      "source": [
        "#plot predictions\n",
        "f, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n",
        "ax1.scatter(predictions,range(0,len(predictions)),alpha=0.2)\n",
        "ax2=sns.distplot(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndvP0KDzrdm3"
      },
      "outputs": [],
      "source": [
        "cutoff=0.86\n",
        "test_data['pred_sentiment']= predictions\n",
        "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment >= cutoff),1,test_data.pred_sentiment)\n",
        "test_data['pred_sentiment'] = np.where((test_data.pred_sentiment < cutoff),0,test_data.pred_sentiment)\n",
        "\n",
        "labels = [0, 1]\n",
        "print(classification_report(test_data['label'].tolist(),test_data['pred_sentiment'].tolist(),labels=labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s818adMZrhyp"
      },
      "outputs": [],
      "source": [
        "final_test=pd.read_csv(\"test.csv\")\n",
        "# final_test=pd.read_csv(\"train.csv\")\n",
        "\n",
        "ftest=final_test.copy()\n",
        "ftest.drop(columns=['id'],axis=1,inplace=True)\n",
        "\n",
        "ftest['text'] = ftest['text'].apply(remove_emoji)\n",
        "ftest['text'] = ftest['text'].apply(clean_text)\n",
        "\n",
        "f_test  = np.array( tokenizer.texts_to_sequences(ftest['text'].tolist()) )\n",
        "f_test = pad_sequences(f_test, padding='post', maxlen=maxlen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "lfL6R5D2eJic"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(f_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxSW1mprrnPr"
      },
      "outputs": [],
      "source": [
        "#plot predictions\n",
        "f, (ax1, ax2) = plt.subplots(1, 2,figsize=(15,5))\n",
        "ax1.scatter(predictions,ftest.index,alpha=0.2)\n",
        "ax2=sns.distplot(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wGxE8NHfeJig",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "ftest['pred_sentiment']= predictions\n",
        "ftest['pred_sentiment'] = np.where((ftest.pred_sentiment >= cutoff),1,ftest.pred_sentiment)\n",
        "ftest['pred_sentiment'] = np.where((ftest.pred_sentiment < cutoff),0,ftest.pred_sentiment)\n",
        "\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "ftest[ftest['pred_sentiment']==1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os7XGIxgeJii",
        "outputId": "33b3b611-7ba5-423b-8030-142d6de03b41"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: ('0' to exit)\n",
            "             text  pred_sentiment\n",
            "0  example string        0.001622\n",
            "1           white        0.830708\n",
            "Input: ('0' to exit)\n",
            "             text  pred_sentiment\n",
            "0  example string        0.001622\n",
            "1            fuck        0.485885\n",
            "Input: ('0' to exit)\n",
            "0\n",
            "Exit successful!!\n"
          ]
        }
      ],
      "source": [
        "# def test1(incoming_string):\n",
        "# print(\"incoming_string (from server): \")\n",
        "# incoming_string = input()\n",
        "\n",
        "flg = 1\n",
        "while flg:\n",
        "\n",
        "  print(\"Input: ('0' to exit)\")\n",
        "  incoming_string = input()\n",
        "  # os.system('clear')\n",
        "  if incoming_string=='0':\n",
        "    print(\"Exit successful!!\")\n",
        "    break\n",
        "\n",
        "  # print(\"hereeeeee\")\n",
        "  a1 = 100\n",
        "  id1 = np.int64(a1)\n",
        "  a2 = 101\n",
        "  id2 = np.int64(a2)\n",
        "\n",
        "\n",
        "  # print(type(incoming_string))\n",
        "\n",
        "  data = {'id': [id1,id2],\n",
        "          'text': ['Example String',incoming_string]\n",
        "          }\n",
        "\n",
        "  final_test = pd.DataFrame(data)\n",
        "  # final_test\n",
        "  # products_list = df.values.tolist()\n",
        "  # print(type(final_test))\n",
        "\n",
        "\n",
        "  # final_test=pd.read_csv(\"test.csv\")\n",
        "\n",
        "  ftest2=final_test.copy()\n",
        "\n",
        "  ftest2.drop(columns=['id'],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  # print(type(ftest))\n",
        "\n",
        "  ftest2['text'] = ftest2['text'].apply(remove_emoji)\n",
        "  ftest2['text'] = ftest2['text'].apply(clean_text)\n",
        "  # print(type(ftest['text'][0]))\n",
        "  f_test  = np.array( tokenizer.texts_to_sequences(ftest2['text'].tolist()) )\n",
        "  f_test = pad_sequences(f_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "  # display((x_test))\n",
        "  # display((f_test))\n",
        "\n",
        "  predictions = model.predict(f_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #mapping prediction to 1 or 0\n",
        "  cutoff = 0.82\n",
        "  ftest2['pred_sentiment']= predictions\n",
        "\n",
        "  # ftest['pred_sentiment'] = np.where((ftest.pred_sentiment >= cutoff),1,ftest.pred_sentiment)\n",
        "  # ftest['pred_sentiment'] = np.where((ftest.pred_sentiment < cutoff),0,ftest.pred_sentiment)\n",
        "\n",
        "\n",
        "\n",
        "  # ///////////////////////////////\n",
        "  # ftest2['pred_sentiment'] = np.where((ftest2.pred_sentiment >= cutoff),1,ftest2.pred_sentiment)\n",
        "  # ftest2['pred_sentiment'] = np.where((ftest2.pred_sentiment < cutoff),0,ftest2.pred_sentiment)\n",
        "  # ///////////////////////////////////////////////////////\n",
        "\n",
        "\n",
        "  # print((ftest['pred_sentiment'][0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  #processed texts categorized as hate speech\n",
        "  # pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "  # ftest[ftest['pred_sentiment']==1]\n",
        "\n",
        "  # final_test.iloc[ftest[ftest['pred_sentiment']==1].index]\n",
        "\n",
        "  # p2 = predictions\n",
        "  # # predictions\n",
        "  # p2.sort()\n",
        "  # print(type(predictions))\n",
        "  # for i in range(100):\n",
        "  print(ftest2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmSBgvVU0uAc"
      },
      "outputs": [],
      "source": [
        "# def test1(incoming_string):\n",
        "# print(\"incoming_string (from server): \")\n",
        "# incoming_string = input()\n",
        "\n",
        "def Predict_input(str1):\n",
        "  flg = 1\n",
        "  # while flg:\n",
        "\n",
        "  # print(\"Input: ('0' to exit)\")\n",
        "  incoming_string = str1\n",
        "  # os.system('clear')\n",
        "  # if incoming_string=='0':\n",
        "    # print(\"Exit successful!!\")\n",
        "    # break\n",
        "\n",
        "  # print(\"hereeeeee\")\n",
        "  a1 = 100\n",
        "  id1 = np.int64(a1)\n",
        "  a2 = 101\n",
        "  id2 = np.int64(a2)\n",
        "\n",
        "\n",
        "  # print(type(incoming_string))\n",
        "\n",
        "  data = {'id': [id1,id2],\n",
        "          'text': ['Example String',incoming_string]\n",
        "          }\n",
        "\n",
        "  final_test = pd.DataFrame(data)\n",
        "  # final_test\n",
        "  # products_list = df.values.tolist()\n",
        "  # print(type(final_test))\n",
        "\n",
        "\n",
        "  # final_test=pd.read_csv(\"test.csv\")\n",
        "\n",
        "  ftest2=final_test.copy()\n",
        "\n",
        "  ftest2.drop(columns=['id'],axis=1,inplace=True)\n",
        "\n",
        "\n",
        "  # print(type(ftest))\n",
        "\n",
        "  ftest2['text'] = ftest2['text'].apply(remove_emoji)\n",
        "  ftest2['text'] = ftest2['text'].apply(clean_text)\n",
        "  # print(type(ftest['text'][0]))\n",
        "  f_test  = np.array( tokenizer.texts_to_sequences(ftest2['text'].tolist()) )\n",
        "  f_test = pad_sequences(f_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "  # display((x_test))\n",
        "  # display((f_test))\n",
        "\n",
        "  predictions = model.predict(f_test)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #mapping prediction to 1 or 0\n",
        "  cutoff = 0.82\n",
        "  ftest2['pred_sentiment']= predictions\n",
        "\n",
        "  # ftest['pred_sentiment'] = np.where((ftest.pred_sentiment >= cutoff),1,ftest.pred_sentiment)\n",
        "  # ftest['pred_sentiment'] = np.where((ftest.pred_sentiment < cutoff),0,ftest.pred_sentiment)\n",
        "\n",
        "\n",
        "\n",
        "  # ///////////////////////////////\n",
        "  ftest2['pred_sentiment'] = np.where((ftest2.pred_sentiment >= cutoff),1,ftest2.pred_sentiment)\n",
        "  ftest2['pred_sentiment'] = np.where((ftest2.pred_sentiment < cutoff),0,ftest2.pred_sentiment)\n",
        "  # ///////////////////////////////////////////////////////\n",
        "\n",
        "\n",
        "  # print((ftest['pred_sentiment'][0]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #processed texts categorized as hate speech\n",
        "  # pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "\n",
        "  # ftest[ftest['pred_sentiment']==1]\n",
        "\n",
        "  # final_test.iloc[ftest[ftest['pred_sentiment']==1].index]\n",
        "\n",
        "  # p2 = predictions\n",
        "  # # predictions\n",
        "  # p2.sort()\n",
        "  # print(type(predictions))\n",
        "  # for i in range(100):\n",
        "  ret = int(ftest2['pred_sentiment'][1])\n",
        "  # print(ret)\n",
        "  return ret\n",
        "# r = Predict_input(\"fuck girl\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVXtlfxwoFad",
        "outputId": "25b13d95-75c4-41d3-8fb4-1f05f150d701"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "# !pip install flask-ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UMULSA7oM-L",
        "outputId": "f5c66c2d-339f-47ba-f778-5f5486af46b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://21b1-35-245-153-21.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:44:28] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> You are a racist person\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:44:41] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> You are a nice person\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[2022-04-20 16:45:29,064] ERROR in app: Exception on / [GET]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
            "    response = self.full_dispatch_request()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1953, in full_dispatch_request\n",
            "    return self.finalize_request(rv)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 1968, in finalize_request\n",
            "    response = self.make_response(rv)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/flask/app.py\", line 2098, in make_response\n",
            "    \"The view function did not return a valid response. The\"\n",
            "TypeError: The view function did not return a valid response. The function either returned None or ended without a return statement.\n",
            "127.0.0.1 - - [20/Apr/2022 16:45:29] \"\u001b[35m\u001b[1mGET / HTTP/1.1\u001b[0m\" 500 -\n",
            "127.0.0.1 - - [20/Apr/2022 16:46:53] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> Your a black nigga\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:47:16] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> Your a black nice nigerian\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:47:34] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> Your a looking like bnanana\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:47:46] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> Your a looking cool\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:48:04] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> Your a looking like a bitch\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:48:29] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> lets travel together and fuck eachother\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:51:20] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> You are a nice person\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:51:27] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> fuck\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:51:53] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> i will fuck you\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:52:00] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> fuck you\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:52:19] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> i will fuck you hard\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:52:39] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> i will fuck hard\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:52:48] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> fuck hard\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:53:09] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> never fuck anyone\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:53:28] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> always fuck girl\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:53:34] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> kiss my ass\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:53:53] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> first kiss was awesome\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:54:19] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> my first kiss in murree was awesome.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:54:43] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> he forcefully kiss me \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:55:46] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> asian racist \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:55:57] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> asian nice people\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:56:11] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> white people are superior than black\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:57:56] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> white people are superior than black\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:58:40] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> whitee people are superior than black\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [20/Apr/2022 16:59:00] \"\u001b[37mPOST / HTTP/1.1\u001b[0m\" 201 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "here-> kiss my ass\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask,request,Response\n",
        "from flask_ngrok import run_with_ngrok\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app)   \n",
        "\n",
        "@app.route(\"/\",methods=['GET', 'POST','DELETE', 'PATCH'])\n",
        "def home():\n",
        "  if request.method == 'POST':\n",
        "    av = request.form.get('name')\n",
        "    print(\"here->\",av)\n",
        "    model_out = Predict_input(av)\n",
        "    model_out_str = str(model_out)\n",
        "    # return Response(\"{'Hate':'1'}\", status=201, mimetype='application/json')\n",
        "    return Response(model_out_str, status=201, mimetype='application/json')\n",
        "\n",
        "app.run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "english1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python [conda env:py3-TF2.0]",
      "language": "python",
      "name": "conda-env-py3-TF2.0-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
